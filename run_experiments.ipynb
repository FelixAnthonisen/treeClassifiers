{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# My implementations\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from itertools import product\n",
    "from sklearn import metrics\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Do data loading, exploration and preprocessing as you see fit.\n",
    "\n",
    "Here is some code to load the dataset to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['citric_acid', 'residual_sugar', 'pH', 'sulphates', 'alcohol']\n",
      "Target column name: type\n",
      "X shape: (500, 5)\n",
      "y shape: (500,)\n",
      "[[ 0.13  1.6   3.34  0.59  9.2 ]\n",
      " [ 0.1   2.8   3.6   0.66 10.2 ]\n",
      " [ 0.32  1.9   3.2   0.55  9.5 ]\n",
      " ...\n",
      " [ 0.36  7.    3.04  0.32 11.  ]\n",
      " [ 0.42  2.1   3.11  0.78 12.4 ]\n",
      " [ 0.15  9.7   3.05  0.3   9.1 ]]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"datasets/wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 4206969\n",
    "np.random.seed(seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 4, 5, 6, 7, 8, 9, 10, 25]\n",
    "criterions = [\"entropy\", \"gini\"]\n",
    "n_estimators = [5, 10, 20, 50]\n",
    "max_features = [\"log2\", \"sqrt\", None]\n",
    "hyperparameter_list = list(product(max_depths, criterions, n_estimators, max_features))\n",
    "def tune_hyperparameters(hyperparameter_list: list[Any], classifier: type) -> tuple[int, str, int, str]:\n",
    "    global seed\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    min_mse = float(\"inf\")\n",
    "    counter = 0\n",
    "    N = len(hyperparameter_list)\n",
    "    for max_depth, criterion, n_estimator, max_feature in hyperparameter_list:\n",
    "        if counter % 5 == 0:\n",
    "                print(f\"{round(counter/N*100, 2)}%\")\n",
    "        counter += 1\n",
    "        val_scores = []\n",
    "        forest = classifier(n_estimators=n_estimator, max_depth=max_depth, criterion=criterion, max_features=max_feature, random_state=seed)\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "            forest.fit(X_train_fold, y_train_fold)\n",
    "            val_score = metrics.mean_squared_error(y_val_fold, forest.predict(X_val_fold))\n",
    "            val_scores.append(val_score)\n",
    "        cv_score = np.mean(val_scores)\n",
    "        if cv_score < min_mse:\n",
    "            min_mse = cv_score\n",
    "            best_max_depth = max_depth\n",
    "            best_criterion = criterion\n",
    "            best_n_estimator = n_estimator\n",
    "            best_max_feature = max_feature\n",
    "\n",
    "    return (best_max_depth, best_criterion, best_n_estimator, best_max_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4206969\n",
      "0.0%\n",
      "2.31%\n",
      "4.63%\n",
      "6.94%\n",
      "9.26%\n",
      "11.57%\n",
      "13.89%\n",
      "16.2%\n",
      "18.52%\n",
      "20.83%\n",
      "23.15%\n",
      "25.46%\n",
      "27.78%\n",
      "30.09%\n",
      "32.41%\n",
      "34.72%\n",
      "37.04%\n",
      "39.35%\n",
      "41.67%\n",
      "43.98%\n",
      "46.3%\n",
      "48.61%\n",
      "50.93%\n",
      "53.24%\n",
      "55.56%\n",
      "57.87%\n",
      "60.19%\n",
      "62.5%\n",
      "64.81%\n",
      "67.13%\n",
      "69.44%\n",
      "71.76%\n",
      "74.07%\n",
      "76.39%\n",
      "78.7%\n",
      "81.02%\n",
      "83.33%\n",
      "85.65%\n",
      "87.96%\n",
      "90.28%\n",
      "92.59%\n",
      "94.91%\n",
      "97.22%\n",
      "99.54%\n",
      "10 gini 5 log2\n",
      "Training accuracy: 0.9057142857142857\n",
      "Validation accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "print(seed)\n",
    "best_max_depth, best_criterion, best_n_estimator, best_max_feature = tune_hyperparameters(hyperparameter_list, RandomForest)\n",
    "print(best_max_depth, best_criterion, best_n_estimator, best_max_feature)\n",
    "forest = RandomForest(n_estimators=best_n_estimator, max_depth=best_max_depth, criterion=best_criterion, max_features=best_max_feature, random_state=seed)\n",
    "forest.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {metrics.accuracy_score(y_train, forest.predict(X_train))}\")\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(y_test, forest.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "2.31%\n",
      "4.63%\n",
      "6.94%\n",
      "9.26%\n",
      "11.57%\n",
      "13.89%\n",
      "16.2%\n",
      "18.52%\n",
      "20.83%\n",
      "23.15%\n",
      "25.46%\n",
      "27.78%\n",
      "30.09%\n",
      "32.41%\n",
      "34.72%\n",
      "37.04%\n",
      "39.35%\n",
      "41.67%\n",
      "43.98%\n",
      "46.3%\n",
      "48.61%\n",
      "50.93%\n",
      "53.24%\n",
      "55.56%\n",
      "57.87%\n",
      "60.19%\n",
      "62.5%\n",
      "64.81%\n",
      "67.13%\n",
      "69.44%\n",
      "71.76%\n",
      "74.07%\n",
      "76.39%\n",
      "78.7%\n",
      "81.02%\n",
      "83.33%\n",
      "85.65%\n",
      "87.96%\n",
      "90.28%\n",
      "92.59%\n",
      "94.91%\n",
      "97.22%\n",
      "99.54%\n",
      "Training accuracy: 0.9485714285714286\n",
      "Validation accuracy: 0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "best_max_depth, best_criterion, best_n_estimator, best_max_feature = tune_hyperparameters(hyperparameter_list, RandomForestClassifier)\n",
    "forest = RandomForestClassifier(n_estimators=best_n_estimator, max_depth=best_max_depth, criterion=best_criterion, max_features=best_max_feature, random_state=seed)\n",
    "forest.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {metrics.accuracy_score(y_train, forest.predict(X_train))}\")\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(y_test, forest.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coffee dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"datasets/wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_depth, best_criterion, best_n_estimator, best_max_feature = tune_hyperparameters(hyperparameter_list, RandomForest)\n",
    "print(best_max_depth, best_criterion, best_n_estimator, best_max_feature)\n",
    "forest = RandomForestClassifier(n_estimators=best_n_estimator, max_depth=best_max_depth, criterion=best_criterion, max_features=best_max_feature, random_state=seed)\n",
    "forest.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {metrics.accuracy_score(y_train, forest.predict(X_train))}\")\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(y_test, forest.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_depth, best_criterion, best_n_estimator, best_max_feature = tune_hyperparameters(hyperparameter_list, RandomForestClassifier)\n",
    "forest = RandomForestClassifier(n_estimators=best_n_estimator, max_depth=best_max_depth, criterion=best_criterion, max_features=best_max_feature, random_state=seed)\n",
    "forest.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {metrics.accuracy_score(y_train, forest.predict(X_train))}\")\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(y_test, forest.predict(X_test))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
