{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# ... add more imports as needed\n",
    "\n",
    "# My implementations\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from itertools import product\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Do data loading, exploration and preprocessing as you see fit.\n",
    "\n",
    "Here is some code to load the dataset to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['citric_acid', 'residual_sugar', 'pH', 'sulphates', 'alcohol']\n",
      "Target column name: type\n",
      "X shape: (500, 5)\n",
      "y shape: (500,)\n",
      "[[ 0.13  1.6   3.34  0.59  9.2 ]\n",
      " [ 0.1   2.8   3.6   0.66 10.2 ]\n",
      " [ 0.32  1.9   3.2   0.55  9.5 ]\n",
      " ...\n",
      " [ 0.36  7.    3.04  0.32 11.  ]\n",
      " [ 0.42  2.1   3.11  0.78 12.4 ]\n",
      " [ 0.15  9.7   3.05  0.3   9.1 ]]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"datasets/wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "Estimators:  1\n",
      "2.314814814814815%\n",
      "Estimators:  5\n",
      "4.62962962962963%\n",
      "Estimators:  20\n",
      "6.944444444444445%\n",
      "Estimators:  5\n",
      "9.25925925925926%\n",
      "Estimators:  10\n",
      "11.574074074074074%\n",
      "Estimators:  1\n",
      "13.88888888888889%\n",
      "Estimators:  10\n",
      "16.203703703703702%\n",
      "Estimators:  20\n",
      "18.51851851851852%\n",
      "Estimators:  5\n",
      "20.833333333333336%\n",
      "Estimators:  20\n",
      "23.14814814814815%\n",
      "Estimators:  1\n",
      "25.462962962962965%\n",
      "Estimators:  10\n",
      "27.77777777777778%\n",
      "Estimators:  1\n",
      "30.09259259259259%\n",
      "Estimators:  5\n",
      "32.407407407407405%\n",
      "Estimators:  20\n",
      "34.72222222222222%\n",
      "Estimators:  5\n",
      "37.03703703703704%\n",
      "Estimators:  10\n",
      "39.351851851851855%\n",
      "Estimators:  1\n",
      "41.66666666666667%\n",
      "Estimators:  10\n",
      "43.98148148148148%\n",
      "Estimators:  20\n",
      "46.2962962962963%\n",
      "Estimators:  5\n",
      "48.61111111111111%\n",
      "Estimators:  20\n",
      "50.92592592592593%\n",
      "Estimators:  1\n",
      "53.24074074074075%\n",
      "Estimators:  10\n",
      "55.55555555555556%\n",
      "Estimators:  1\n",
      "57.870370370370374%\n",
      "Estimators:  5\n",
      "60.18518518518518%\n",
      "Estimators:  20\n",
      "62.5%\n",
      "Estimators:  5\n",
      "64.81481481481481%\n",
      "Estimators:  10\n",
      "67.12962962962963%\n",
      "Estimators:  1\n",
      "69.44444444444444%\n",
      "Estimators:  10\n",
      "71.75925925925925%\n",
      "Estimators:  20\n",
      "74.07407407407408%\n",
      "Estimators:  5\n",
      "76.38888888888889%\n",
      "Estimators:  20\n",
      "78.70370370370371%\n",
      "Estimators:  1\n",
      "81.01851851851852%\n",
      "Estimators:  10\n",
      "83.33333333333334%\n",
      "Estimators:  1\n",
      "85.64814814814815%\n",
      "Estimators:  5\n",
      "87.96296296296296%\n",
      "Estimators:  20\n",
      "90.27777777777779%\n",
      "Estimators:  5\n",
      "92.5925925925926%\n",
      "Estimators:  10\n",
      "94.9074074074074%\n",
      "Estimators:  1\n",
      "97.22222222222221%\n",
      "Estimators:  10\n",
      "99.53703703703704%\n",
      "Estimators:  20\n",
      "9 gini 20 log2\n"
     ]
    }
   ],
   "source": [
    "max_depths = [3, 4, 5, 6, 7, 8, 9, 10, 25]\n",
    "criterions = [\"entropy\", \"gini\"]\n",
    "n_estimators = [1, 5, 10, 20]\n",
    "max_features = [\"log2\", \"sqrt\", None]\n",
    "hyperparameter_list = list(product(max_depths, criterions, n_estimators, max_features))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "min_mse = float(\"inf\")\n",
    "counter = 0\n",
    "N = len(hyperparameter_list)\n",
    "for max_depth, criterion, n_estimator, max_feature in hyperparameter_list:\n",
    "    if counter % 5 == 0:\n",
    "        print(f\"{counter/N*100}%\")\n",
    "        print(\"Estimators: \", n_estimator)\n",
    "    counter += 1\n",
    "    val_scores = []\n",
    "    forest = RandomForest(n_estimators=n_estimator, max_depth=max_depth, criterion=criterion, max_features=max_feature)\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        forest.fit(X_train_fold, y_train_fold)\n",
    "        val_score = metrics.mean_squared_error(y_val_fold, forest.predict(X_val_fold))\n",
    "        val_scores.append(val_score)\n",
    "    cv_score = np.mean(val_scores)\n",
    "    if cv_score < min_mse:\n",
    "        min_mse = cv_score\n",
    "        best_max_depth = max_depth\n",
    "        best_criterion = criterion\n",
    "        best_n_estimator = n_estimator\n",
    "        best_max_feature = max_feature\n",
    "\n",
    "print(best_max_depth, best_criterion, best_n_estimator, best_max_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9914285714285714\n",
      "Validation accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForest(n_estimators=best_max_depth, max_depth=best_max_depth, criterion=best_criterion, max_features=best_max_feature)\n",
    "forest.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {metrics.accuracy_score(y_train, forest.predict(X_train))}\")\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(y_test, forest.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "Estimators:  1\n",
      "2.314814814814815%\n",
      "Estimators:  5\n",
      "4.62962962962963%\n",
      "Estimators:  20\n",
      "6.944444444444445%\n",
      "Estimators:  5\n",
      "9.25925925925926%\n",
      "Estimators:  10\n",
      "11.574074074074074%\n",
      "Estimators:  1\n",
      "13.88888888888889%\n",
      "Estimators:  10\n",
      "16.203703703703702%\n",
      "Estimators:  20\n",
      "18.51851851851852%\n",
      "Estimators:  5\n",
      "20.833333333333336%\n",
      "Estimators:  20\n",
      "23.14814814814815%\n",
      "Estimators:  1\n",
      "25.462962962962965%\n",
      "Estimators:  10\n",
      "27.77777777777778%\n",
      "Estimators:  1\n",
      "30.09259259259259%\n",
      "Estimators:  5\n",
      "32.407407407407405%\n",
      "Estimators:  20\n",
      "34.72222222222222%\n",
      "Estimators:  5\n",
      "37.03703703703704%\n",
      "Estimators:  10\n",
      "39.351851851851855%\n",
      "Estimators:  1\n",
      "41.66666666666667%\n",
      "Estimators:  10\n",
      "43.98148148148148%\n",
      "Estimators:  20\n",
      "46.2962962962963%\n",
      "Estimators:  5\n",
      "48.61111111111111%\n",
      "Estimators:  20\n",
      "50.92592592592593%\n",
      "Estimators:  1\n",
      "53.24074074074075%\n",
      "Estimators:  10\n",
      "55.55555555555556%\n",
      "Estimators:  1\n",
      "57.870370370370374%\n",
      "Estimators:  5\n",
      "60.18518518518518%\n",
      "Estimators:  20\n",
      "62.5%\n",
      "Estimators:  5\n",
      "64.81481481481481%\n",
      "Estimators:  10\n",
      "67.12962962962963%\n",
      "Estimators:  1\n",
      "69.44444444444444%\n",
      "Estimators:  10\n",
      "71.75925925925925%\n",
      "Estimators:  20\n",
      "74.07407407407408%\n",
      "Estimators:  5\n",
      "76.38888888888889%\n",
      "Estimators:  20\n",
      "78.70370370370371%\n",
      "Estimators:  1\n",
      "81.01851851851852%\n",
      "Estimators:  10\n",
      "83.33333333333334%\n",
      "Estimators:  1\n",
      "85.64814814814815%\n",
      "Estimators:  5\n",
      "87.96296296296296%\n",
      "Estimators:  20\n",
      "90.27777777777779%\n",
      "Estimators:  5\n",
      "92.5925925925926%\n",
      "Estimators:  10\n",
      "94.9074074074074%\n",
      "Estimators:  1\n",
      "97.22222222222221%\n",
      "Estimators:  10\n",
      "99.53703703703704%\n",
      "Estimators:  20\n",
      "8 entropy 20 sqrt\n"
     ]
    }
   ],
   "source": [
    "max_depths = [3, 4, 5, 6, 7, 8, 9, 10, 25]\n",
    "criterions = [\"entropy\", \"gini\"]\n",
    "n_estimators = [1, 5, 10, 20]\n",
    "max_features = [\"log2\", \"sqrt\", None]\n",
    "hyperparameter_list = list(product(max_depths, criterions, n_estimators, max_features))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "min_mse = float(\"inf\")\n",
    "counter = 0\n",
    "N = len(hyperparameter_list)\n",
    "for max_depth, criterion, n_estimator, max_feature in hyperparameter_list:\n",
    "    if counter % 5 == 0:\n",
    "        print(f\"{counter/N*100}%\")\n",
    "        print(\"Estimators: \", n_estimator)\n",
    "    counter += 1\n",
    "    val_scores = []\n",
    "    forest = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth, criterion=criterion, max_features=max_feature)\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        forest.fit(X_train_fold, y_train_fold)\n",
    "        val_score = metrics.mean_squared_error(y_val_fold, forest.predict(X_val_fold))\n",
    "        val_scores.append(val_score)\n",
    "    cv_score = np.mean(val_scores)\n",
    "    if cv_score < min_mse:\n",
    "        min_mse = cv_score\n",
    "        best_max_depth = max_depth\n",
    "        best_criterion = criterion\n",
    "        best_n_estimator = n_estimator\n",
    "        best_max_feature = max_feature\n",
    "\n",
    "print(best_max_depth, best_criterion, best_n_estimator, best_max_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98\n",
      "Validation accuracy: 0.8733333333333333\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=best_max_depth, max_depth=best_max_depth, criterion=best_criterion, max_features=best_max_feature)\n",
    "forest.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {metrics.accuracy_score(y_train, forest.predict(X_train))}\")\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(y_test, forest.predict(X_test))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
